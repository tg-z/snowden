# Tokyo

The Internet is fundamentally American, but I had to leave America to fully
understand what that meant. The World Wide Web might have been invented in
Geneva, at the CERN research laboratory in 1989, but the ways by which the Web
is accessed are as American as baseball, which gives the American Intelligence
Community the home field advantage. The cables and satellites, the servers and
towers—so much of the infrastructure of the Internet is under US control that
over 90 percent of the world’s Internet traffic passes through technologies
developed, owned, and/or operated by the American government and American
businesses, most of which are physically located on American territory.
Countries that traditionally worry about such advantages, like China and
Russia, have attempted to make alternative systems, such as the Great
Firewall, or the state-sponsored censored search engines, or the nationalized
satellite constellations that provide selective GPS—but America remains the
hegemon, the keeper of the master switches that can turn almost anyone on and
off at will.

It’s not just the Internet’s infrastructure that I’m defining as fundamentally
American—it’s the computer software (Microsoft, Google, Oracle) and hardware
(HP, Apple, Dell), too. It’s everything from the chips (Intel, Qualcomm), to
the routers and modems (Cisco, Juniper), to the Web services and platforms
that provide email and social networking and cloud storage (Google, Facebook,
and the most structurally important but invisible Amazon, which provides cloud
services to the US government along with half the Internet). Though some of
these companies might manufacture their devices in, say, China, the companies
themselves are American and are subject to American law. The problem is,
they’re also subject to classified American policies that pervert law and
permit the US government to surveil virtually every man, woman, and child who
has ever touched a computer or picked up a phone.

Given the American nature of the planet’s communications infrastructure, it
should have been obvious that the US government would engage in this type of
mass surveillance. It should have been especially obvious to me. Yet it
wasn’t—mostly because the government kept insisting that it did nothing of the
sort, and generally disclaimed the practice in courts and in the media in a
manner so adamant that the few remaining skeptics who accused it of lying were
treated like wild-haired conspiracy junkies. Their suspicions about secret NSA
programs seemed hardly different from paranoid delusions involving alien
messages being beamed to the radios in our teeth. We—me, you, all of us—were
too trusting. But what makes this all the more personally painful for me was
that the last time I’d made this mistake, I’d supported the invasion of Iraq
and joined the army. When I arrived in the IC, I felt sure that I’d never be
fooled again, especially given my top secret clearance. Surely that had to
count for some degree of transparency. After all, why would the government
keep secrets from its secret keepers? This is all to say that the obvious
didn’t even become the thinkable for me until some time after I moved to Japan
in 2009 to work for the NSA, America’s premier signals intelligence agency.

It was a dream job, not only because it was with the most advanced
intelligence agency on the planet, but also because it was based in Japan, a
place that had always fascinated Lindsay and me. It felt like a country from
the future. Though mine was officially a contractor position, its
responsibilities and, especially, its location were more than enough to lure
me. It’s ironic that only by going private again was I put in a position to
understand what my government was doing.

On paper, I was an employee of Perot Systems, a company founded by that
diminutive hyperactive Texan who founded the Reform Party and twice ran for
the presidency. But almost immediately after my arrival in Japan, Perot
Systems was acquired by Dell, so on paper I became an employee of Dell. As in
the CIA, this contractor status was all just formality and cover, and I only
ever worked in an NSA facility.

The NSA’s Pacific Technical Center (PTC) occupied one-half of a building
inside the enormous Yokota Air Base. As the headquarters of US Forces Japan,
the base was surrounded by high walls, steel gates, and guarded checkpoints.
Yokota and the PTC were just a short bike ride from where Lindsay and I got an
apartment in Fussa, a city at the western edge of Tokyo’s vast metropolitan
spread.

The PTC handled the NSA’s infrastructure for the entire Pacific, and provided
support for the agency’s spoke sites in nearby countries. Most of these were
focused on managing the secret relationships that let the NSA cover the
Pacific Rim with spy gear, as long as the agency promised to share some of the
intelligence it gleaned with regional governments—and so long as their
citizens didn’t find out what the agency was doing. Communications
interception was the major part of the mission. The PTC would amass “cuts”
from captured signals and push them back across the ocean to Hawaii, and
Hawaii, in turn, would push them back to the continental United States.

My official job title was systems analyst, with responsibility for maintaining
the local NSA systems, though much of my initial work was that of a systems
administrator, helping to connect the NSA’s systems architecture with the
CIA’s. Because I was the only one in the region who knew the CIA’s
architecture, I’d also travel out to US embassies, like the one I’d left in
Geneva, establishing and maintaining the links that enabled the agencies to
share intelligence in ways that hadn’t previously been possible. This was the
first time in my life that I truly realized the power of being the only one in
a room with a sense not just of how one system functioned internally, but of
how it functioned together with multiple systems—or didn’t. Later, as the
chiefs of the PTC came to recognize that I had a knack for hacking together
solutions to their problems, I was given enough of a leash to propose projects
of my own.

Two things about the NSA stunned me right off the bat: how technologically
sophisticated it was compared with the CIA, and how much less vigilant it was
about security in its every iteration, from the compartmentalization of
information to data encryption. In Geneva, we’d had to haul the hard drives
out of the computer every night and lock them up in a safe—and what’s more,
those drives were encrypted. The NSA, by contrast, hardly bothered to encrypt
anything.

In fact, it was rather disconcerting to find out that the NSA was so far ahead
of the game in terms of cyberintelligence yet so far behind it in terms of
cybersecurity, including the most basic: disaster recovery, or backup. Each of
the NSA’s spoke sites collected its own intel, stored the intel on its own
local servers, and, because of bandwidth restrictions—limitations on the
amount of data that could be transmitted at speed—often didn’t send copies
back to the main servers at NSA headquarters. This meant that if any data were
destroyed at a particular site, the intelligence that the agency had worked
hard to collect could be lost.

My chiefs at the PTC understood the risks the agency was taking by not keeping
copies of many of its files, so they tasked me with engineering a solution and
pitching it to the decision makers at headquarters. The result was a backup
and storage system that would act as a shadow NSA: a complete, automated, and
constantly updating copy of all of the agency’s most important material, which
would allow the agency to reboot and be up and running again, with all its
archives intact, even if Fort Meade were reduced to smoldering rubble.

The major problem with creating a global disaster-recovery system—or really
with creating any type of backup system that involves a truly staggering
number of computers—is dealing with duplicated data. In plain terms, you have
to handle situations in which, say, one thousand computers all have copies of
the same single file: you have to make sure you’re not backing up that same
file one thousand times, because that would require one thousand times the
amount of bandwidth and storage space. It was this wasteful duplication, in
particular, that was preventing the agency’s spoke sites from transmitting
daily backups of their records to Fort Meade: the connection would be clogged
with a thousand copies of the same file containing the same intercepted phone
call, 999 of which the agency did not need.

The way to avoid this was “deduplication”: a method to evaluate the uniqueness
of data. The system that I designed would constantly scan the files at every
facility at which the NSA stored records, testing each “block” of data down to
the slightest fragment of a file to find out whether or not it was unique.
Only if the agency lacked a copy of it back home would the data be
automatically queued for transmission—reducing the volume that flowed over the
agency’s transpacific fiber-optic connection from a waterfall to a trickle.

The combination of deduplication and constant improvements in storage
technology allowed the agency to store intelligence data for progressively
longer periods of time. Just over the course of my career, the agency’s goal
went from being able to store intelligence for days, to weeks, to months, to
five years or more after its collection. By the time of this book’s
publication, the agency might already be able to store it for decades. The
NSA’s conventional wisdom was that there was no point in collecting anything
unless they could store it until it was useful, and there was no way to
predict when exactly that would be. This rationalization was fuel for the
agency’s ultimate dream, which is permanency—to store all of the files it has
ever collected or produced for perpetuity, and so create a perfect memory. The
permanent record.

The NSA has a whole protocol you’re supposed to follow when you give a program
a code name. It’s basically an I Ching–like stochastic procedure that randomly
picks words from two columns. An internal website throws imaginary dice to
pick one name from column A, and throws again to pick one name from column B.
This is how you end up with names that don’t mean anything, like FOXACID and
EGOTISTICALGIRAFFE. The point of a code name is that it’s not supposed to
refer to what the program does. (As has been reported, FOXACID was the code
name for NSA servers that host malware versions of familiar websites;
EGOTISTICALGIRAFFE was an NSA program intended to exploit a vulnerability in
certain Web browsers running Tor, since they couldn’t break Tor itself.) But
agents at the NSA were so confident of their power and the agency’s absolute
invulnerability that they rarely complied with the regulations. In short,
they’d cheat and redo their dice throws until they got the name combination
they wanted, whatever they thought was cool: TRAFFICTHIEF, the VPN Attack
Orchestrator.

I swear I never did that when I went about finding a name for my backup
system. I swear that I just rolled the bones and came up with EPICSHELTER.

Later, once the agency adopted the system, they renamed it something like the
Storage Modernization Plan or Storage Modernization Program. Within two years
of the invention of EPICSHELTER, a variant had been implemented and was in
standard use under yet another name.

* * *

THE MATERIAL THAT I disseminated to journalists in 2013 documented such an
array of abuses by the NSA, accomplished through such a diversity of
technological capabilities, that no one agent in the daily discharge of their
responsibilities was ever in the position to know about all of them—not even a
systems administrator. To find out about even a fraction of the malfeasance,
you had to go searching. And to go searching, you had to know that it existed.

It was something as banal as a conference that first clued me in to that
existence, sparking my initial suspicion about the full scope of what the NSA
was perpetrating.

In the midst of my EPICSHELTER work, the PTC hosted a conference on China
sponsored by the Joint Counterintelligence Training Academy (JCITA) for the
Defense Intelligence Agency (DIA), an agency connected to the Department of
Defense that specializes in spying on foreign militaries and foreign
military–related matters. This conference featured briefings given by experts
from all the intelligence components, the NSA, CIA, FBI, and military, about
how the Chinese intelligence services were targeting the IC and what the IC
could do to cause them trouble. Though China certainly interested me, this
wasn’t the kind of work I would ordinarily have been involved in, so I didn’t
pay the conference much mind until it was announced that the only technology
briefer was unable to attend at the last minute. I’m not sure what the reason
was for that absence—maybe flu, maybe kismet—but the course chair for the
conference asked if there was anyone at the PTC who might be able to step in
as a replacement, since it was too late to reschedule. One of the chiefs
mentioned my name, and when I was asked if I wanted to give it a shot, I said
yes. I liked my boss, and wanted to help him out. Also, I was curious, and
relished the opportunity to do something that wasn’t about data deduplication
for a change.

My boss was thrilled. Then he told me the catch: the briefing was the next
day.

I called Lindsay and told her I wouldn’t be home. I was going to be up all
night preparing the presentation, whose nominal topic was the intersection
between a very old discipline, counterintelligence, and a very new discipline,
cyberintelligence, coming together to try to exploit and thwart the
adversary’s attempts to use the Internet to gather surveillance. I started
pulling everything off the NSA network (and off the CIA network, to which I
still had access), trying to read every top secret report I could find about
what the Chinese were doing online. Specifically, I read up on so-called
intrusion sets, which are bundles of data about particular types of attacks,
tools, and targets. IC analysts used these intrusion sets to identify specific
Chinese military cyberintelligence or hacking groups, in the same way that
detectives might try to identify a suspect responsible for a string of
burglaries by a common set of characteristics or modus operandi.

The point of my researching this widely dispersed material was to do more than
merely report on how China was hacking us, however. My primary task was to
provide a summary of the IC’s assessment of China’s ability to electronically
track American officers and assets operating in the region.

Everyone knows (or thinks they know) about the draconian Internet measures of
the Chinese government, and some people know (or think they know) the gravamen
of the disclosures I gave to journalists in 2013 about my own government’s
capabilities. But listen: It’s one thing to casually say, in a science-fiction
dystopic type of way, that a government can theoretically see and hear
everything that all of its citizens are doing. It’s a very different thing for
a government to actually try to implement such a system. What a science-
fiction writer can describe in a sentence might take the concerted work of
thousands of technologists and millions of dollars of equipment. To read the
technical details of China’s surveillance of private communications—to read a
complete and accurate accounting of the mechanisms and machinery required for
the constant collection, storage, and analysis of the billions of daily
telephone and Internet communications of over a billion people—was utterly
mind-boggling. At first I was so impressed by the system’s sheer achievement
and audacity that I almost forgot to be appalled by its totalitarian controls.

After all, China’s government was an explicitly antidemocratic single-party
state. NSA agents, even more than most Americans, just took it for granted
that the place was an authoritarian hellhole. Chinese civil liberties weren’t
my department. There wasn’t anything I could do about them. I worked, I was
sure of it, for the good guys, and that made me a good guy, too.

But there were certain aspects of what I was reading that disturbed me. I was
reminded of what is perhaps the fundamental rule of technological progress: if
something can be done, it probably will be done, and possibly already has
been. There was simply no way for America to have so much information about
what the Chinese were doing without having done some of the very same things
itself, and I had the sneaking sense while I was looking through all this
China material that I was looking at a mirror and seeing a reflection of
America. What China was doing publicly to its own citizens, America might
be—could be—doing secretly to the world.

And although you should hate me for it, I have to say that at the time I
tamped down my unease. Indeed, I did my best to ignore it. The distinctions
were still fairly clear to me. China’s Great Firewall was domestically
censorious and repressive, intended to keep its citizens in and America out in
the most chilling and demonstrative way, while the American systems were
invisible and purely defensive. As I then understood US surveillance, anyone
in the world could come in through America’s Internet infrastructure and
access whatever content they pleased, unblocked and unfiltered—or at least
only blocked and filtered by their home countries and American businesses,
which are, presumptively, not under US government control. It was only those
who’d been expressly targeted for visiting, for example, jihadist bombing
sites or malware marketplaces who would find themselves tracked and
scrutinized.

Understood this way, the US surveillance model was perfectly okay with me. It
was more than okay, actually—I fully supported defensive and targeted
surveillance, a “firewall” that didn’t keep anybody out, but just burned the
guilty.

But in the sleepless days after that sleepless night, some dim suspicion still
stirred in my mind. Long after I gave my China briefing, I couldn’t help but
keep digging around.

* * *

AT THE START of my employment with the NSA, in 2009, I was only slightly more
knowledgeable about its practices than the rest of the world. From
journalists’ reports, I was aware of the agency’s myriad surveillance
initiatives authorized by President George W. Bush in the immediate aftermath
of 9/11. In particular, I knew about its most publicly contested initiative,
the warrantless wiretapping component of the President’s Surveillance Program
(PSP), which had been disclosed by the _New York Times_ in 2005 thanks to the
courage of a few NSA and Department of Justice whistleblowers.

Officially speaking, the PSP was an “executive order,” essentially a set of
instructions set down by the American president that the government has to
consider the equal of public law—even if they’re just scribbled secretly on a
napkin. The PSP empowered the NSA to collect telephone and Internet
communications between the United States and abroad. Notably, the PSP allowed
the NSA to do this without having to obtain a special warrant from a Foreign
Intelligence Surveillance Court, a secret federal court established in 1978 to
oversee IC requests for surveillance warrants after the agencies were caught
domestically spying on the anti–Vietnam War and civil rights movements.

Following the outcry that attended the _Times_ revelations, and American Civil
Liberties Union challenges to the constitutionality of the PSP in non-secret,
regular courts, the Bush administration claimed to have let the program expire
in 2007. But the expiration turned out to be a farce. Congress spent the last
two years of the Bush administration passing legislation that retroactively
legalized the PSP. It also retroactively immunized from prosecution the
telecoms and Internet service providers that had participated in it. This
legislation—the Protect America Act of 2007 and the FISA Amendments Act of
2008—employed intentionally misleading language to reassure US citizens that
their communications were not being explicitly targeted, even as it
effectively extended the PSP’s remit. In addition to collecting inbound
communications coming from foreign countries, the NSA now also had policy
approval for the warrantless collection of outbound telephone and Internet
communications originating within American borders.

That, at least, was the picture I got after reading the government’s own
summary of the situation, which was issued to the public in an unclassified
version in July 2009, the very same summer that I spent delving into Chinese
cyber-capabilities. This summary, which bore the nondescript title
_Unclassified Report on the President’s Surveillance Program_ , was compiled
by the Offices of the Inspector Generals of five agencies (Department of
Defense, Department of Justice, CIA, NSA, and the Office of the Director of
National Intelligence) and was offered to the public in lieu of a full
congressional investigation of Bush-era NSA overreach. The fact that President
Obama, once in office, refused to call for a full congressional investigation
was the first sign, to me at least, that the new president—for whom Lindsay
had enthusiastically campaigned—intended to move forward without a proper
reckoning with the past. As his administration rebranded and recertified PSP-
related programs, Lindsay’s hope in him, as well as my own, would prove more
and more misplaced.

While the unclassified report was mostly just old news, I found it informative
in a few respects. I remember being immediately struck by its curious, they-
do-protest-too-much tone, along with more than a few twists of logic and
language that didn’t compute. As the report laid out its legal arguments in
support of various agency programs—rarely named, and almost never described—I
couldn’t help but notice the fact that hardly any of the executive branch
officials who had actually authorized these programs had agreed to be
interviewed by the inspector generals. From Vice President Dick Cheney and his
counsel David Addington to Attorney General John Ashcroft and DOJ lawyer John
Yoo, nearly every major player had refused to cooperate with the very offices
responsible for holding the IC accountable, and the IGs couldn’t compel them
to cooperate, because this wasn’t a formal investigation involving testimony.
It was hard for me to interpret their absence from the record as anything
other than an admission of malfeasance.

Another aspect of the report that threw me was its repeated, obscure
references to “Other Intelligence Activities” (the capitalization is the
report’s) for which no “viable legal rationale” or no “legal basis” could be
found beyond President Bush’s claim of executive powers during wartime—a
wartime that had no end in sight. Of course, these references gave no
description whatsoever of what these Activities might actually be, but the
process of deduction pointed to warrantless domestic surveillance, as it was
pretty much the only intelligence activity not provided for under the various
legal frameworks that appeared subsequent to the PSP.

As I read on, I wasn’t sure that anything disclosed in the report completely
justified the legal machinations involved, let alone the threats by then
deputy attorney general James Comey and then FBI director Robert Mueller to
resign if certain aspects of the PSP were reauthorized. Nor did I notice
anything that fully explained the risks taken by so many fellow agency
members—agents much senior to me, with decades of experience—and DOJ personnel
to contact the press and express their misgivings about how aspects of the PSP
were being abused. If they were putting their careers, their families, and
their lives on the line, it had to be over something graver than the
warrantless wiretapping that had already made headlines.

That suspicion sent me searching for the classified version of the report, and
it was not in the least dispelled by the fact that such a version appeared not
to exist. I didn’t understand. If the classified version was merely a record
of the sins of the past, it should have been easily accessible. But it was
nowhere to be found. I wondered whether I was looking in the wrong places.
After a while of ranging fairly widely and still finding nothing, though, I
decided to drop the issue. Life took over and I had work to do. When you get
asked to give recommendations on how to keep IC agents and assets from being
uncovered and executed by the Chinese Ministry of State Security, it’s hard to
remember what you were Googling the week before.

It was only later, long after I’d forgotten about the missing IG report, that
the classified version came skimming across my desktop, as if in proof of that
old maxim that the best way to find something is to stop looking for it. Once
the classified version turned up, I realized why I hadn’t had any luck finding
it previously: it couldn’t be seen, not even by the heads of agencies. It was
filed in an Exceptionally Controlled Information (ECI) compartment, an
extremely rare classification used only to make sure that something would
remain hidden even from those holding top secret clearance. Because of my
position, I was familiar with most of the ECIs at the NSA, but not this one.
The report’s full classification designation was TOP
SECRET//STLW//HCS/COMINT//ORCON/NOFORN, which translates to: pretty much only
a few dozen people in the world are allowed to read this.

I was most definitely not one of them. The report came to my attention by
mistake: someone in the NSA IG’s office had left a draft copy on a system that
I, as a sysadmin, had access to. Its caveat of STLW, which I didn’t recognize,
turned out to be what’s called a “dirty word” on my system: a label signifying
a document that wasn’t supposed to be stored on lower-security drives. These
drives were being constantly checked for any newly appearing dirty words, and
the moment one was found I was alerted so that I could decide how best to
scrub the document from the system. But before I did, I’d have to examine the
offending file myself, just to confirm that the dirty word search hadn’t
flagged anything accidentally. Usually I’d take just the briefest glance at
the thing. But this time, as soon I opened the document and read the title, I
knew I’d be reading it all the way through.

Here was everything that was missing from the unclassified version. Here was
everything that the journalism I’d read had lacked, and that the court
proceedings I’d followed had been denied: a complete accounting of the NSA’s
most secret surveillance programs, and the agency directives and Department of
Justice policies that had been used to subvert American law and contravene the
US Constitution. After reading the thing, I could understand why no IC
employee had ever leaked it to journalists, and no judge would be able to
force the government to produce it in open court. The document was so deeply
classified that anybody who had access to it who wasn’t a sysadmin would be
immediately identifiable. And the activities it outlined were so deeply
criminal that no government would ever allow it to be released unredacted.

One issue jumped out at me immediately: it was clear that the unclassified
version I was already familiar with wasn’t a redaction of the classified
version, as would usually be the practice. Rather, it was a wholly different
document, which the classified version immediately exposed as an outright and
carefully concocted lie. The duplicity was stupefying, especially given that
I’d just dedicated months of my time to deduplicating files. Most of the time,
when you’re dealing with two versions of the same document, the differences
between them are trivial—a few commas here, a few words there. But the only
thing these two particular reports had in common was their title.

Whereas the unclassified version merely made reference to the NSA being
ordered to intensify its intelligence-gathering practices following 9/11, the
classified version laid out the nature, and scale, of that intensification.
The NSA’s historic brief had been fundamentally altered from targeted
collection of communications to “bulk collection,” which is the agency’s
euphemism for mass surveillance. And whereas the unclassified version
obfuscated this shift, advocating for expanded surveillance by scaring the
public with the specter of terror, the classified version made this shift
explicit, justifying it as the legitimate corollary of expanded technological
capability.

The NSA IG’s portion of the classified report outlined what it called “a
collection gap,” noting that existing surveillance legislation (particularly
the Foreign Intelligence Surveillance Act) dated from 1978, a time when most
communications signals traveled via radio or telephone lines, rather than
fiber-optic cables and satellites. In essence, the agency was arguing that the
speed and volume of contemporary communication had outpaced, and outgrown,
American law—no court, not even a secret court, could issue enough
individually targeted warrants fast enough to keep up—and that a truly global
world required a truly global intelligence agency. All of this pointed, in the
NSA’s logic, to the necessity of the bulk collection of Internet
communications. The code name for this bulk collection initiative was
indicated in the very “dirty word” that got it flagged on my system: STLW, an
abbreviation of STELLARWIND. This turned out to be the single major component
of the PSP that had continued, and even grown, in secret after the rest of the
program had been made public in the press.

STELLARWIND was the classified report’s deepest secret. It was, in fact, the
NSA’s deepest secret, and the one that the report’s sensitive status had been
designed to protect. The program’s very existence was an indication that the
agency’s mission had been transformed, from using technology to defend America
to using technology to control it by redefining citizens’ private Internet
communications as potential signals intelligence.

Such fraudulent redefinitions ran throughout the report, but perhaps the most
fundamental and transparently desperate involved the government’s vocabulary.
STELLARWIND had been collecting communications since the PSP’s inception in
2001, but in 2004—when Justice Department officials balked at the continuation
of the initiative—the Bush administration attempted to legitimize it ex post
facto by changing the meanings of basic English words, such as “acquire” and
“obtain.” According to the report, it was the government’s position that the
NSA could collect whatever communications records it wanted to, without having
to get a warrant, because it could only be said to have _acquired_ or
_obtained_ them, in the legal sense, if and when the agency “searched for and
retrieved” them from its database.

This lexical sophistry was particularly galling to me, as I was well aware
that the agency’s goal was to be able to retain as much data as it could for
as long as it could—for perpetuity. If communications records would only be
considered definitively “obtained” once they were used, they could remain
“unobtained” but collected in storage forever, raw data awaiting its future
manipulation. By redefining the terms “acquire” and “obtain”—from describing
the act of data being entered into a database, to describing the act of a
person (or, more likely, an algorithm) querying that database and getting a
“hit” or “return” at any conceivable point in the future—the US government was
developing the capacity of an eternal law-enforcement agency. At any time, the
government could dig through the past communications of anyone it wanted to
victimize in search of a crime (and everybody’s communications contain
evidence of something). At any point, for all perpetuity, any new
administration—any future rogue head of the NSA—could just show up to work
and, as easily as flicking a switch, instantly track everybody with a phone or
a computer, know who they were, where they were, what they were doing with
whom, and what they had ever done in the past.

* * *

THE TERM “MASS surveillance” is more clear to me, and I think to most people,
than the government’s preferred “bulk collection,” which to my mind threatens
to give a falsely fuzzy impression of the agency’s work. “Bulk collection”
makes it sound like a particularly busy post office or sanitation department,
as opposed to a historic effort to achieve total access to—and clandestinely
take possession of—the records of all digital communications in existence.

But even once a common ground of terminology is established, misperceptions
can still abound. Most people, even today, tend to think of mass surveillance
in terms of content—the actual words they use when they make a phone call or
write an email. When they find out that the government actually cares
comparatively little about that content, they tend to care comparatively
little about government surveillance. This relief is understandable, to a
degree, due to what each of us must regard as the uniquely revealing and
intimate nature of our communications: the sound of our voice, almost as
personal as a thumbprint; the inimitable facial expression we put on in a
selfie sent by text. The unfortunate truth, however, is that the content of
our communications is rarely as revealing as its other elements—the unwritten,
unspoken information that can expose the broader context and patterns of
behavior.

The NSA calls this “metadata.” The term’s prefix, “meta,” which traditionally
is translated as “above” or “beyond,” is here used in the sense of “about”:
metadata is data about data. It is, more accurately, data that is made by
data—a cluster of tags and markers that allow data to be useful. The most
direct way of thinking about metadata, however, is as “activity data,” all the
records of all the things you do on your devices and all the things your
devices do on their own. Take a phone call, for example: its metadata might
include the date and time of the call, the call’s duration, the number from
which the call was made, the number being called, and their locations. An
email’s metadata might include information about what type of computer it was
generated on, where, and when, who the computer belonged to, who sent the
email, who received it, where and when it was sent and received, and who if
anyone besides the sender and recipient accessed it, and where and when.
Metadata can tell your surveillant the address you slept at last night and
what time you got up this morning. It reveals every place you visited during
your day and how long you spent there. It shows who you were in touch with and
who was in touch with you.

It’s this fact that obliterates any government claim that metadata is somehow
not a direct window into the substance of a communication. With the dizzying
volume of digital communications in the world, there is simply no way that
every phone call could be listened to or email could be read. Even if it were
feasible, however, it still wouldn’t be useful, and anyway, metadata makes
this unnecessary by winnowing the field. This is why it’s best to regard
metadata not as some benign abstraction, but as the very essence of content:
it is precisely the first line of information that the party surveilling you
requires.

There’s another thing, too: content is usually defined as something that you
knowingly produce. You know what you’re saying during a phone call, or what
you’re writing in an email. But you have hardly any control over the metadata
you produce, because it is generated automatically. Just as it’s collected,
stored, and analyzed by machine, it’s made by machine, too, without your
participation or even consent. Your devices are constantly communicating for
you whether you want them to or not. And, unlike the humans you communicate
with of your own volition, your devices don’t withhold private information or
use code words in an attempt to be discreet. They merely ping the nearest cell
phone towers with signals that never lie.

One major irony here is that law, which always lags behind technological
innovation by at least a generation, gives substantially more protections to a
communication’s content than to its metadata—and yet intelligence agencies are
far more interested in the metadata—the activity records that allow them both
the “big picture” ability to analyze data at scale, and the “little picture”
ability to make perfect maps, chronologies, and associative synopses of an
individual person’s life, from which they presume to extrapolate predictions
of behavior. In sum, metadata can tell your surveillant virtually everything
they’d ever want or need to know about you, except what’s actually going on
inside your head.

After reading this classified report, I spent the next weeks, even months, in
a daze. I was sad and low, trying to deny everything I was thinking and
feeling—that’s what was going on in my head, toward the end of my stint in
Japan.

I felt far from home, but monitored. I felt more adult than ever, but also
cursed with the knowledge that all of us had been reduced to something like
children, who’d be forced to live the rest of our lives under omniscient
parental supervision. I felt like a fraud, making excuses to Lindsay to
explain my sullenness. I felt like a fool, as someone of supposedly serious
technical skills who’d somehow helped to build an essential component of this
system without realizing its purpose. I felt used, as an employee of the IC
who only now was realizing that all along I’d been protecting not my country
but the state. I felt, above all, violated. Being in Japan only accentuated
the sense of betrayal.

I’ll explain.

The Japanese that I’d managed to pick up through community college and my
interests in anime and manga was enough for me to speak and get through basic
conversations, but reading was a different matter. In Japanese, each word can
be represented by its own unique character, or a combination of characters,
called kanji, so there were tens of thousands of them—far too many for me to
memorize. Often, I was only able to decode particular kanji if they were
written with their phonetic gloss, the _furigana_ , which are most commonly
meant for foreigners and young readers and so are typically absent from public
texts like street signs. The result of all this was that I walked around
functionally illiterate. I’d get confused and end up going right when I should
have gone left, or left when I should have gone right. I’d wander down the
wrong streets and misorder from menus. I was a stranger, is what I’m saying,
and often lost, in more ways than one. There were times when I’d accompany
Lindsay out on one of her photography trips into the countryside and I’d
suddenly stop and realize, in the midst of a village or in the middle of a
forest, that I knew nothing whatsoever about my surroundings.

And yet: everything was known about me. I now understood that I was totally
transparent to my government. The phone that gave me directions, and corrected
me when I went the wrong way, and helped me translate the traffic signs, and
told me the times of the buses and trains, was also making sure that all of my
doings were legible to my employers. It was telling my bosses where I was and
when, even if I never touched the thing and just left it in my pocket.

I remember forcing myself to laugh about this once when Lindsay and I got lost
on a hike and Lindsay—to whom I’d told nothing—just spontaneously said, “Why
don’t you text Fort Meade and have them find us?” She kept the joke going, and
I tried to find it funny but couldn’t. “Hello,” she mimicked me, “can you help
us with directions?”

Later I would live in Hawaii, near Pearl Harbor, where America was attacked
and dragged into what might have been its last just war. Here, in Japan, I was
closer to Hiroshima and Nagasaki, where that war ignominiously ended. Lindsay
and I had always hoped to visit those cities, but every time we planned to go
we wound up having to cancel. On one of my first days off, we were all set to
head down Honshu to Hiroshima, but I was called in to work and told to go in
the opposite direction—to Misawa Air Base in the frozen north. On the day of
our next scheduled attempt, Lindsay got sick, and then I got sick, too.
Finally, the night before we intended to go to Nagasaki, Lindsay and I were
woken by our first major earthquake, jumped up from our futon, ran down seven
flights of stairs, and spent the rest of the night out on the street with our
neighbors, shivering in our pajamas.

To my true regret, we never went. Those places are holy places, whose
memorials honor the two hundred thousand incinerated and the countless
poisoned by fallout while reminding us of technology’s amorality.

I think often of what’s called the “atomic moment”—a phrase that in physics
describes the moment when a nucleus coheres the protons and neutrons spinning
around it into an atom, but that’s popularly understood to mean the advent of
the nuclear age, whose isotopes enabled advances in energy production,
agriculture, water potability, and the diagnosis and treatment of deadly
disease. It also created the atomic bomb.

Technology doesn’t have a Hippocratic oath. So many decisions that have been
made by technologists in academia, industry, the military, and government
since at least the Industrial Revolution have been made on the basis of “can
we,” not “should we.” And the intention driving a technology’s invention
rarely, if ever, limits its application and use.

I do not mean, of course, to compare nuclear weapons with cybersurveillance in
terms of human cost. But there is a commonality when it comes to the concepts
of proliferation and disarmament.

The only two countries I knew of that had previously practiced mass
surveillance were those two other major combatants of World War II—one
America’s enemy, the other America’s ally. In both Nazi Germany and Soviet
Russia, the earliest public indications of that surveillance took the
superficially innocuous form of a census, the official enumeration and
statistical recording of a population. The First All-Union Census of the
Soviet Union, in 1926, had a secondary agenda beyond a simple count: it
overtly queried Soviet citizens about their nationality. Its findings
convinced the ethnic Russians who comprised the Soviet elite that they were in
the minority when compared to the aggregated masses of citizens who claimed a
Central Asian heritage, such as Uzbeks, Kazakhs, Tajiks, Turkmen, Georgians,
and Armenians. These findings significantly strengthened Stalin’s resolve to
eradicate these cultures, by “reeducating” their populations in the
deracinating ideology of Marxism-Leninism.

The Nazi German census of 1939 took on a similar statistical project, but with
the assistance of computer technology. It set out to count the Reich’s
population in order to control it and to purge it—mainly of Jews and
Roma—before exerting its murderous efforts on populations beyond its borders.
To effect this, the Reich partnered with Dehomag, a German subsidiary of the
American IBM, which owned the patent to the punch card tabulator, a sort of
analog computer that counted holes punched into cards. Each citizen was
represented by a card, and certain holes on the cards represented certain
markers of identity. Column 22 addressed the religion rubric: hole 1 was
Protestant, hole 2 Catholic, and hole 3 Jewish. Shortly thereafter, this
census information was used to identify and deport Europe’s Jewish population
to the death camps.

A single current-model smartphone commands more computing power than all of
the wartime machinery of the Reich and the Soviet Union combined. Recalling
this is the surest way to contextualize not just the modern American IC’s
technological dominance, but also the threat it poses to democratic
governance. In the century or so since those census efforts, technology has
made astounding progress, but the same could not be said for the law or human
scruples that could restrain it.

The United States has a census, too, of course. The Constitution established
the American census and enshrined it as the official federal count of each
state’s population in order to determine its proportional delegation to the
House of Representatives. That was something of a revisionist principle, in
that authoritarian governments, including the British monarchy that ruled the
colonies, had traditionally used the census as a method of assessing taxes and
ascertaining the number of young men eligible for military conscription. It
was the Constitution’s genius to repurpose what had been a mechanism of
oppression into one of democracy. The census, which is officially under the
jurisdiction of the Senate, was ordered to be performed every ten years, which
was roughly the amount of time it took to process the data of most American
censuses following the first census of 1790. This decade-long lag was
shortened by the census of 1890, which was the world’s first census to make
use of computers (the prototypes of the models that IBM later sold to Nazi
Germany). With computing technology, the processing time was cut in half.

Digital technology didn’t just further streamline such accounting—it is
rendering it obsolete. Mass surveillance is now a never-ending census,
substantially more dangerous than any questionnaire sent through the mail. All
our devices, from our phones to our computers, are basically miniature census-
takers we carry in our backpacks and in our pockets—census-takers that
remember everything and forgive nothing.

Japan was my atomic moment. It was then that I realized where these new
technologies were headed, and that if my generation didn’t intervene the
escalation would only continue. It would be a tragedy if, by the time we’d
finally resolved to resist, such resistance were futile. The generations to
come would have to get used to a world in which surveillance wasn’t something
occasional and directed in legally justified circumstances, but a constant and
indiscriminate presence: the ear that always hears, the eye that always sees,
a memory that is sleepless and permanent.

Once the ubiquity of collection was combined with the permanency of storage,
all any government had to do was select a person or a group to scapegoat and
go searching—as I’d gone searching through the agency’s files—for evidence of
a suitable crime.

